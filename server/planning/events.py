# -*- coding: utf-8; -*-
#
# This file is part of Superdesk.
#
# Copyright 2013, 2014 Sourcefabric z.u. and contributors.
#
# For the full copyright and license information, please see the
# AUTHORS and LICENSE files distributed with this source code, or
# at https://www.sourcefabric.org/superdesk/license

"""Superdesk Events"""

import superdesk
import logging
from superdesk import get_resource_service
from superdesk.resource import Resource
from superdesk.errors import SuperdeskApiError
from superdesk.metadata.utils import generate_guid
from superdesk.metadata.item import GUID_NEWSML
from superdesk.notification import push_notification
from apps.archive.common import set_original_creator, get_user
from superdesk.users.services import current_user_has_privilege
from superdesk.utc import utcnow
from .common import STATE_SCHEMA, PUB_STATUS_VALUES
from dateutil.rrule import rrule, YEARLY, MONTHLY, WEEKLY, DAILY, MO, TU, WE, TH, FR, SA, SU
from eve.defaults import resolve_default_values
from eve.methods.common import resolve_document_etag
from eve.utils import config, ParsedRequest, date_to_str
from flask import current_app as app, json
import itertools
import copy
import pytz
import re

logger = logging.getLogger(__name__)

not_analyzed = {'type': 'string', 'index': 'not_analyzed'}
not_indexed = {'type': 'string', 'index': 'no'}

FREQUENCIES = {'DAILY': DAILY, 'WEEKLY': WEEKLY, 'MONTHLY': MONTHLY, 'YEARLY': YEARLY}
DAYS = {'MO': MO, 'TU': TU, 'WE': WE, 'TH': TH, 'FR': FR, 'SA': SA, 'SU': SU}

organizer_roles = {
    'eorol:artAgent': 'Artistic agent',
    'eorol:general': 'General organiser',
    'eorol:tech': 'Technical organiser',
    'eorol:travAgent': 'Travel agent',
    'eorol:venue': 'Venue organiser'
}


class EventsService(superdesk.Service):
    """Service class for the events model."""

    def post_in_mongo(self, docs, **kwargs):
        for doc in docs:
            resolve_default_values(doc, app.config['DOMAIN'][self.datasource]['defaults'])
        self.on_create(docs)
        resolve_document_etag(docs, self.datasource)
        ids = self.backend.create_in_mongo(self.datasource, docs, **kwargs)
        self.on_created(docs)
        return ids

    def patch_in_mongo(self, id, document, original):
        res = self.backend.update_in_mongo(self.datasource, id, document, original)
        return res

    def set_ingest_provider_sequence(self, item, provider):
        """Sets the value of ingest_provider_sequence in item.

        :param item: object to which ingest_provider_sequence to be set
        :param provider: ingest_provider object, used to build the key name of sequence
        """
        sequence_number = get_resource_service('sequences').get_next_sequence_number(
            key_name='ingest_providers_{_id}'.format(_id=provider[config.ID_FIELD]),
            max_seq_number=app.config['MAX_VALUE_OF_INGEST_SEQUENCE']
        )
        item['ingest_provider_sequence'] = str(sequence_number)

    def on_create(self, docs):
        # events generated by recurring rules
        generated_events = []
        for event in docs:
            # generates an unique id
            if 'guid' not in event:
                event['guid'] = generate_guid(type=GUID_NEWSML)
            event['_id'] = event['guid']
            # set the author
            set_original_creator(event)

            # overwrite expiry date
            overwrite_event_expiry_date(event)

            # generates events based on recurring rules
            if event['dates'].get('recurring_rule', None):
                generated_events.extend(generate_recurring_events(event))
                # remove the event that contains the recurring rule. We don't need it anymore
                docs.remove(event)
        if generated_events:
            docs.extend(generated_events)

    def on_created(self, docs):
        """Send WebSocket Notifications for created Events

        Generate the list of IDs for recurring and non-recurring events
        Then send this list off to the clients so they can fetch these events
        """
        notifications_sent = []

        for doc in docs:
            event_type = 'events:created'
            event_id = str(doc.get(config.ID_FIELD))
            user_id = str(doc.get('original_creator', ''))

            if doc.get('recurrence_id'):
                event_type = 'events:created:recurring'
                event_id = str(doc['recurrence_id'])

            # Don't send notification if one has already been sent
            # This is to ensure recurring events doesn't send multiple notifications
            if event_id in notifications_sent:
                continue

            notifications_sent.append(event_id)
            push_notification(
                event_type,
                item=event_id,
                user=user_id
            )

    def can_edit(self, item, user_id):
        # Check privileges
        if not current_user_has_privilege('planning_event_management'):
            return False, 'User does not have sufficient permissions.'
        return True, ''

    def update(self, id, updates, original):
        item = self.backend.update(self.datasource, id, updates, original)
        return item

    def on_update(self, updates, original):
        """Update single or series of recurring events.

        Determine if the supplied event is a single event or a
        series of recurring events, and call the appropriate method
        for the event type.
        """
        if 'skip_on_update' in updates:
            # this is a recursive update (see below)
            del updates['skip_on_update']
            return

        user = get_user()
        user_id = user.get(config.ID_FIELD) if user else None

        if user_id:
            updates['version_creator'] = user_id

        lock_user = original.get('lock_user', None)
        str_user_id = str(user.get(config.ID_FIELD)) if user_id else None

        if lock_user and str(lock_user) != str_user_id:
            raise SuperdeskApiError.forbiddenError('The item was locked by another user')

        # Run the specific methods based on if the original is a
        # single or a series of recurring events
        if not original.get('dates', {}).get('recurring_rule', None):
            self._update_single_event(updates, original)
        else:
            self._update_recurring_events(updates, original)

    def _update_single_event(self, updates, original):
        """Updates the metadata and occurrence of a single event.

        If recurring_rule is provided, we convert this single event into
        a series of recurring events, otherwise we simply update this event.
        """

        # Determine if we're to convert this single event to a recurring series of events
        if updates.get('dates', {}).get('recurring_rule', None) is not None:
            generated_events = self._convert_to_recurring_event(updates, original)

            push_notification(
                'events:updated:recurring',
                item=str(original[config.ID_FIELD]),
                user=str(updates.get('version_creator', '')),
                recurrence_id=str(generated_events[0]['recurrence_id'])
            )
        else:
            push_notification(
                'events:updated',
                item=str(original[config.ID_FIELD]),
                user=str(updates.get('version_creator', ''))
            )

    def _update_recurring_events(self, updates, original):
        """Method to update recurring events.

        If the recurring_rule has been removed for this event, process
        it separately, otherwise update the event and/or its recurring rules
        """
        merged = copy.deepcopy(original)
        merged.update(updates)

        if updates.get('dates'):
            if not updates['dates'].get('recurring_rule', None):
                # Recurring rule has been removed for this event,
                # Remove this rule and return from this method
                self._remove_recurring_rules(updates, original)
                push_notification(
                    'events:updated',
                    item=str(original[config.ID_FIELD]),
                    user=str(updates.get('version_creator'))
                )
                return

            # Generate the list of changes to the series of events based on the
            # new recurring_rules
            new_events, updated_events, deleted_events = self._update_recurring_rules(updates, original)
        else:
            # We only update events here, so get the list of future events
            updated_events = self._get_future_events(merged)
            new_events = deleted_events = []

        # Create instances for the new events, and save them to mongo/elastic
        # Then fire off events for them
        added_events = []
        for e in new_events:
            event = copy.deepcopy(merged)
            event['dates']['start'] = e['dates']['start']
            event['dates']['end'] = e['dates']['end']
            event['_id'] = event['guid'] = generate_guid(type=GUID_NEWSML)
            added_events.append(event)

        if added_events:
            self.create(added_events)
            app.on_inserted_events(added_events)

        # For all the deleted events, remove them from mongo/elastic
        # Then fire off events for them
        for e in deleted_events:
            self.delete({'_id': e[config.ID_FIELD]})
            app.on_deleted_item_events(e)

        # For all the updated events, update their dates/metadata
        # Then fire off events for them
        for e in updated_events:
            if e[config.ID_FIELD] == original[config.ID_FIELD]:
                continue
            updated_event = copy.deepcopy(updates)

            if 'dates' not in updated_event:
                updated_event['dates'] = original['dates']

            if 'guid' in updated_event:
                del updated_event['guid']

            updated_event['dates']['start'] = e['dates']['start']
            updated_event['dates']['end'] = e['dates']['end']
            updated_event['skip_on_update'] = True
            self.patch(e[config.ID_FIELD], updated_event)
            app.on_updated_events(updated_event, {'_id': e[config.ID_FIELD]})

        # And finally push a notification to connected clients
        push_notification(
            'events:updated:recurring',
            item=str(original[config.ID_FIELD]),
            recurrence_id=str(original['recurrence_id']),
            user=str(updates.get('version_creator', ''))
        )

    def _remove_recurring_rules(self, updates, original):
        """Remove recurring rules for an event

        This will also spike all future events in the series
        """
        updates['dates']['recurring_rule'] = None
        updates['recurrence_id'] = None

        # we spike all the related recurrent events
        spike_service = get_resource_service('events_spike')
        for e in self._get_future_events(original):
            updated_event = spike_service.patch(e[config.ID_FIELD], {})
            app.on_updated_events_spike(updated_event, e)

    def _convert_to_recurring_event(self, updates, original):
        """Convert a single event to a series of recurring events"""
        # Convert the single event to a series of recurring events
        merged = copy.deepcopy(original)
        merged.update(updates)
        generated_events = generate_recurring_events(merged)

        # Remove the first element in the list (the current event being updated)
        # And update the start/end dates to be in line with the new recurring rules
        updated_event = generated_events.pop(0)
        updates['dates']['start'] = updated_event['dates']['start']
        updates['dates']['end'] = updated_event['dates']['end']

        # Create the new events and generate their history
        self.create(generated_events)
        app.on_inserted_events(generated_events)
        return generated_events

    def _update_recurring_rules(self, updates, original):
        """Generate a list of changes to events for the new recurring rules

        This will return a list for new, updated and deleted events,
        which is used for updating elastic/mongo.
        """
        new_events = []
        deleted_events = []
        updated_events = []

        merged = copy.deepcopy(original)
        merged.update(updates)

        existing_events = list(self._get_future_events(original))
        existing_events.append(merged)

        # Compute the difference between start and end in the updated event
        time_delta = updates['dates']['end'] - updates['dates']['start']

        # Generate the dates for the following events
        dates = [date for date in itertools.islice(generate_recurring_dates(
            start=merged['dates']['start'],
            tz=merged['dates'].get('tz') and pytz.timezone(merged['dates']['tz'] or None),
            **merged['dates']['recurring_rule']
        ), 0, 200)]

        for event, date in itertools.zip_longest(existing_events, dates):
            if not date:
                # Date is not present so the current event should be deleted
                deleted_events.append(event)
            elif not event:
                # The event is not present so a new event should be created
                new_events.append({
                    'dates': {
                        'start': date,
                        'end': date + time_delta
                    }
                })
            elif event[config.ID_FIELD] == original[config.ID_FIELD]:
                updates['dates']['start'] = date
                updates['dates']['end'] = date + time_delta
            else:
                updated_events.append({
                    '_id': event[config.ID_FIELD],
                    'dates': {
                        'start': date,
                        'end': date + time_delta
                    }
                })

        return new_events, updated_events, deleted_events

    def _get_future_events(self, event):
        """Utility method to get future events for the supplied event"""
        query = {
            '$and': [
                # All the events created from the same recurring rules
                {'recurrence_id': event['recurrence_id']},

                # Only future events
                {'dates.start': {'$gt': date_to_str(event['dates']['start'])}},

                # Except the provided event
                {'_id': {'$ne': event[config.ID_FIELD]}}
            ]
        }

        req = ParsedRequest()
        req.sort = '[("dates.start", 1)]'
        req.where = json.dumps(query)
        return self.get_from_mongo(req, {})

    def get_recurring_timeline(self, selected):
        """Utility method to get all events in the series

        This splits up the series of events into 3 separate arrays.
        Historic: event.dates.start < utcnow()
        Past: utcnow() < event.dates.start < selected.dates.start
        Future: event.dates.start > selected.dates.start
        """
        historic = []
        past = []
        future = []

        selected_start = selected.get('dates', {}).get('start', utcnow())

        req = ParsedRequest()
        req.sort = '[("dates.start", 1)]'
        req.where = json.dumps({
            '$and': [
                {'recurrence_id': selected['recurrence_id']},
                {'_id': {'$ne': selected[config.ID_FIELD]}}
            ]
        })

        for event in list(self.get_from_mongo(req, {})):
            end = event['dates']['end']
            if end < utcnow():
                historic.append(event)
            elif end < selected_start:
                past.append(event)
            elif end > selected_start:
                future.append(event)

        return historic, past, future


events_schema = {
    # Identifiers
    '_id': {'type': 'string', 'unique': True},
    'guid': {
        'type': 'string',
        'unique': True,
        'mapping': not_analyzed
    },
    'unique_id': {
        'type': 'integer',
        'unique': True,
    },
    'unique_name': {
        'type': 'string',
        'unique': True,
        'mapping': not_analyzed
    },
    'version': {
        'type': 'integer'
    },
    'ingest_id': {
        'type': 'string',
        'mapping': not_analyzed
    },
    'recurrence_id': {
        'type': 'string',
        'mapping': not_analyzed,
        'nullable': True,
    },

    # Audit Information
    'original_creator': superdesk.Resource.rel('users', nullable=True),
    'version_creator': superdesk.Resource.rel('users'),
    'firstcreated': {
        'type': 'datetime'
    },
    'versioncreated': {
        'type': 'datetime'
    },

    # Ingest Details
    'ingest_provider': superdesk.Resource.rel('ingest_providers'),
    'source': {     # The value is copied from the ingest_providers vocabulary
        'type': 'string'
    },
    'original_source': {    # This value is extracted from the ingest
        'type': 'string',
        'mapping': not_analyzed
    },
    'ingest_provider_sequence': {
        'type': 'string',
        'mapping': not_analyzed
    },
    'event_created': {
        'type': 'datetime'
    },
    'event_lastmodified': {
        'type': 'datetime'
    },
    # Event Details
    # NewsML-G2 Event properties See IPTC-G2-Implementation_Guide 15.2
    'name': {
        'type': 'string',
        'required': True,
    },
    'definition_short': {'type': 'string'},
    'definition_long': {'type': 'string'},
    'anpa_category': {
        'type': 'list',
        'nullable': True,
        'mapping': {
            'type': 'object',
            'properties': {
                'qcode': not_analyzed,
                'name': not_analyzed,
            }
        }
    },
    'files': {
        'type': 'list',
        'nullable': True,
        'schema': superdesk.Resource.rel('events_files'),
        'mapping': not_analyzed,
    },
    'relationships': {
        'type': 'dict',
        'schema': {
            'broader': {'type': 'string'},
            'narrower': {'type': 'string'},
            'related': {'type': 'string'}
        },
    },
    'links': {
        'type': 'list',
        'nullable': True
    },

    # NewsML-G2 Event properties See IPTC-G2-Implementation_Guide 15.4.3
    'dates': {
        'type': 'dict',
        'schema': {
            'start': {'type': 'datetime'},
            'end': {'type': 'datetime'},
            'tz': {'type': 'string'},
            'duration': {'type': 'string'},
            'confirmation': {'type': 'string'},
            'recurring_date': {
                'type': 'list',
                'nullable': True,
                'mapping': {
                    'type': 'date'
                }
            },
            'recurring_rule': {
                'type': 'dict',
                'schema': {
                    'frequency': {'type': 'string'},
                    'interval': {'type': 'integer'},
                    'endRepeatMode': {'type': 'string'},
                    'until': {'type': 'datetime', 'nullable': True},
                    'count': {'type': 'integer', 'nullable': True},
                    'bymonth': {'type': 'string', 'nullable': True},
                    'byday': {'type': 'string', 'nullable': True},
                    'byhour': {'type': 'string', 'nullable': True},
                    'byminute': {'type': 'string', 'nullable': True},
                },
                'nullable': True
            },
            'occur_status': {
                'nullable': True,
                'type': 'dict',
                'mapping': {
                    'properties': {
                        'qcode': not_analyzed,
                        'name': not_analyzed
                    }
                },
                'schema': {
                    'qcode': {'type': 'string'},
                    'name': {'type': 'string'},
                }
            },
            'ex_date': {
                'type': 'list',
                'mapping': {
                    'type': 'date'
                }
            },
            'ex_rule': {
                'type': 'dict',
                'schema': {
                    'frequency': {'type': 'string'},
                    'interval': {'type': 'string'},
                    'until': {'type': 'datetime', 'nullable': True},
                    'count': {'type': 'integer', 'nullable': True},
                    'bymonth': {'type': 'string', 'nullable': True},
                    'byday': {'type': 'string', 'nullable': True},
                    'byhour': {'type': 'string', 'nullable': True},
                    'byminute': {'type': 'string', 'nullable': True}
                }
            }
        }
    },  # end dates
    'occur_status': {
        'type': 'dict',
        'schema': {
            'qcode': {'type': 'string'},
            'name': {'type': 'string'}
        }
    },
    'news_coverage_status': {
        'type': 'dict',
        'schema': {
            'qcode': {'type': 'string'},
            'name': {'type': 'string'}
        }
    },
    'registration': {
        'type': 'string'
    },
    'access_status': {
        'type': 'list',
        'mapping': {
            'properties': {
                'qcode': not_analyzed,
                'name': not_analyzed
            }
        }
    },

    # Content metadata
    'subject': {
        'type': 'list',
        'mapping': {
            'properties': {
                'qcode': not_analyzed,
                'name': not_analyzed
            }
        }
    },
    'slugline': {
        'type': 'string',
        'mapping': {
            'type': 'string',
            'fields': {
                'phrase': {
                    'type': 'string',
                    'analyzer': 'phrase_prefix_analyzer',
                    'search_analyzer': 'phrase_prefix_analyzer'
                }
            }
        }
    },

    # Item metadata
    'location': {
        'type': 'list',
        'mapping': {
            'properties': {
                'qcode': {'type': 'string'},
                'name': {'type': 'string'},
                'geo': {'type': 'string'},
                'type': {
                    'type': 'string',
                    'default': 'Unclassified',
                }
            }
        }
    },
    'participant': {
        'type': 'list',
        'mapping': {
            'properties': {
                'qcode': not_analyzed,
                'name': not_analyzed
            }
        }
    },
    'participant_requirement': {
        'type': 'list',
        'mapping': {
            'properties': {
                'qcode': not_analyzed,
                'name': not_analyzed
            }
        }
    },
    'organizer': {
        'type': 'list',
        'mapping': {
            'properties': {
                'qcode': not_analyzed,
                'name': not_analyzed
            }
        }
    },
    'event_contact_info': {
        'type': 'list',
        'mapping': {
            'properties': {
                'qcode': not_analyzed,
                'name': not_analyzed
            }
        }
    },
    'event_language': {  # TODO: this is only placeholder schema
        'type': 'list',
        'mapping': {
            'properties': {
                'qcode': not_analyzed,
                'name': not_analyzed
            }
        }
    },

    # These next two are for spiking/unspiking and purging events
    'state': STATE_SCHEMA,
    'expiry': {
        'type': 'datetime',
        'nullable': True
    },
    # says if the event is for internal usage or published
    'pubstatus': {
        'type': 'string',
        'allowed': PUB_STATUS_VALUES,
        'mapping': not_analyzed,
        'nullable': True,
    },

    'lock_user': Resource.rel('users'),
    'lock_time': {
        'type': 'datetime',
        'versioned': False
    },
    'lock_session': Resource.rel('auth'),

    'lock_action': {
        'type': 'string',
        'mapping': not_analyzed,
        'nullable': True
    }
}  # end events_schema


class EventsResource(superdesk.Resource):
    """Resource for events data model

    See IPTC-G2-Implementation_Guide (version 2.21) Section 15.4 for schema details
    """

    url = 'events'
    schema = events_schema
    item_url = 'regex("[\w,.:-]+")'
    resource_methods = ['GET', 'POST']
    datasource = {
        'source': 'events',
        'search_backend': 'elastic',
    }
    item_methods = ['GET', 'PATCH', 'PUT']
    public_methods = ['GET']
    privileges = {'POST': 'planning_event_management',
                  'PATCH': 'planning_event_management'}


def generate_recurring_dates(start, frequency, interval=1, endRepeatMode='unlimited',
                             until=None, byday=None, count=None, tz=None):
    """

    Returns list of dates related to recurring rules

    :param start datetime: date when to start
    :param frequency str: DAILY, WEEKLY, MONTHLY, YEARLY
    :param interval int: indicates how often the rule repeats as a positive integer
    :param until datetime: date after which the recurrence rule expires
    :param byday str or list: "MO TU"
    :param count int: number of occurrences of the rule
    :return list: list of datetime

    """
    # if tz is given, respect the timzone by starting from the local time
    # NOTE: rrule uses only naive datetime
    if tz:
        try:
            # start can already be localized
            start = pytz.UTC.localize(start)
        except ValueError:
            pass
        start = start.astimezone(tz).replace(tzinfo=None)
        if until:
            until = until.astimezone(tz).replace(tzinfo=None)

    # check format of the recurring_rule byday value
    if byday and re.match(r'^-?[1-5]+.*', byday):
        # byday uses monthly or yearly frequency rule with day of week and
        # preceeding day of month intenger byday value
        # examples:
        # 1FR - first friday of the month
        # -2MON - second to last monday of the month
        if byday[:1] == '-':
            day_of_month = int(byday[:2])
            day_of_week = byday[2:]
        else:
            day_of_month = int(byday[:1])
            day_of_week = byday[1:]

        byweekday = DAYS.get(day_of_week)(day_of_month)
    else:
        # byday uses DAYS constants
        byweekday = byday and [DAYS.get(d) for d in byday.split()] or None
    # TODO: use dateutil.rrule.rruleset to incude ex_date and ex_rule
    dates = rrule(
        FREQUENCIES.get(frequency),
        dtstart=start,
        until=until,
        byweekday=byweekday,
        count=count,
        interval=interval,
    )
    # if a timezone has been applied, returns UTC
    if tz:
        return (tz.localize(dt).astimezone(pytz.UTC).replace(tzinfo=None) for dt in dates)
    else:
        return (date for date in dates)


def setRecurringMode(event):
    endRepeatMode = event.get('dates', {}).get('recurring_rule', {}).get('endRepeatMode')
    if endRepeatMode == 'unlimited':
        event['dates']['recurring_rule']['count'] = None
        event['dates']['recurring_rule']['until'] = None
    elif endRepeatMode == 'count':
        event['dates']['recurring_rule']['until'] = None
    elif endRepeatMode == 'until':
        event['dates']['recurring_rule']['count'] = None


def overwrite_event_expiry_date(event):
    if 'expiry' in event:
        event['expiry'] = event['dates']['end']


def generate_recurring_events(event):
    generated_events = []
    setRecurringMode(event)

    # Get the recurrence_id, or generate one if it doesn't exist
    recurrence_id = event.get('recurrence_id', generate_guid(type=GUID_NEWSML))

    # compute the difference between start and end in the original event
    time_delta = event['dates']['end'] - event['dates']['start']
    # for all the dates based on the recurring rules:
    for date in itertools.islice(generate_recurring_dates(
            start=event['dates']['start'],
            tz=event['dates'].get('tz') and pytz.timezone(event['dates']['tz'] or None),
            **event['dates']['recurring_rule']
    ), 0, 200):  # set a limit to prevent too many events to be created
        # create event with the new dates
        new_event = copy.deepcopy(event)
        new_event['dates']['start'] = date
        new_event['dates']['end'] = date + time_delta
        # set a unique guid
        new_event['guid'] = generate_guid(type=GUID_NEWSML)
        new_event['_id'] = new_event['guid']
        # set the recurrence id
        new_event['recurrence_id'] = recurrence_id

        # set expiry date
        overwrite_event_expiry_date(new_event)

        generated_events.append(new_event)

    return generated_events
